# ACE í”„ë ˆì„ì›Œí¬ ì‚¬ìš© ê°€ì´ë“œ

**Agentic Context Engineering (ACE)** í”„ë ˆì„ì›Œí¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ìì‹ ì˜ ë°ì´í„°ë¡œ LLM ì„±ëŠ¥ì„ ê°œì„ í•˜ëŠ” ì™„ì „í•œ ê°€ì´ë“œì…ë‹ˆë‹¤.

## ëª©ì°¨

1. [ê°œìš”](#ê°œìš”)
2. [í™˜ê²½ ì„¤ì •](#í™˜ê²½-ì„¤ì •)
3. [ë°ì´í„°ì…‹ ì¤€ë¹„](#ë°ì´í„°ì…‹-ì¤€ë¹„)
4. [ì‹¤í–‰ ê°€ì´ë“œ](#ì‹¤í–‰-ê°€ì´ë“œ)
5. [ì„±ëŠ¥ ë¹„êµ](#ì„±ëŠ¥-ë¹„êµ)
6. [ì‹¤ì „ ì˜ˆì œ](#ì‹¤ì „-ì˜ˆì œ)
7. [ë¬¸ì œ í•´ê²°](#ë¬¸ì œ-í•´ê²°)

---

## ê°œìš”

### ACEê°€ í•˜ëŠ” ì¼

ACEëŠ” LLMì´ **ë§¥ë½(context)ì„ í•™ìŠµ**í•˜ì—¬ ì„±ëŠ¥ì„ ê°œì„ í•˜ëŠ” í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤:

```
ì´ˆê¸° ìƒíƒœ (ë¹ˆ í”Œë ˆì´ë¶)
  â†“
í•™ìŠµ (ì˜¤í”„ë¼ì¸ ì ì‘)
  â†“
ì§„í™”ëœ í”Œë ˆì´ë¶ (ì „ëµ, ê³µì‹, í•¨ì • ë“±)
  â†“
ê°œì„ ëœ ì„±ëŠ¥ (ì˜¨ë¼ì¸ ì¶”ë¡ )
```

### ê¸°ëŒ€ íš¨ê³¼

- **ì •í™•ë„ í–¥ìƒ**: 33% â†’ 100% (í…ŒìŠ¤íŠ¸ ê²°ê³¼ ê¸°ì¤€)
- **ë„ë©”ì¸ ì§€ì‹ ì¶•ì **: ì‘ì—…ë³„ ì „ëµê³¼ íŒ¨í„´ í•™ìŠµ
- **ì ì§„ì  ê°œì„ **: ë°ì´í„°ê°€ ì¶”ê°€ë ìˆ˜ë¡ ê³„ì† ë°œì „

---

## í™˜ê²½ ì„¤ì •

### 1. Python í™˜ê²½ (pyenv)

```bash
# í˜„ì¬ ì„¤ì •ëœ Python ë²„ì „ í™•ì¸
cat .python-version
# ì¶œë ¥: ace-poc (Python 3.12.11 ê¸°ë°˜)

# í™˜ê²½ í™œì„±í™” (ìë™ í™œì„±í™”ë˜ì§€ ì•Šì€ ê²½ìš°)
pyenv activate ace-poc
```

### 2. ì˜ì¡´ì„± ì„¤ì¹˜

```bash
pip install -r requirements.txt
```

**requirements.txt ë‚´ìš©**:
```
pydantic>=2.0.0
orjson>=3.9.0
python-dotenv>=1.0.0
anthropic>=0.18.0
httpx>=0.24.0
numpy>=1.24.0
tqdm>=4.65.0
pytest>=7.4.0
```

### 3. API í‚¤ ì„¤ì •

```bash
# .env íŒŒì¼ ìƒì„±
cp .env.example .env

# .env íŒŒì¼ í¸ì§‘
# ANTHROPIC_API_KEY=your_key_here
```

**.env íŒŒì¼ ì˜ˆì œ**:
```bash
# API Configuration
ANTHROPIC_API_KEY=sk-ant-api03-xxxx
ACE_MODEL=claude-3-5-sonnet-latest
ACE_MAX_TOKENS=2048
ACE_TEMPERATURE=0.0
ACE_SEED=42

# Storage
ACE_STORAGE_DIR=./storage
ACE_RUNS_DIR=./runs

# Playbook Tuning
ACE_HARMFUL_THRESHOLD=3
ACE_DEDUP_SIMILARITY=0.92
ACE_MAX_OPERATIONS_PER_CURATOR=20

# Semantic Deduplication (ì„ íƒì‚¬í•­)
ACE_USE_SEMANTIC_DEDUP=false
ACE_EMBEDDING_MODEL=all-MiniLM-L6-v2
```

#### ê³ ê¸‰ ê¸°ëŠ¥: ì˜ë¯¸ ê¸°ë°˜ ì¤‘ë³µ ì œê±° (ì„ íƒì‚¬í•­)

ACEëŠ” ì„ íƒì ìœ¼ë¡œ **ì˜ë¯¸ ê¸°ë°˜ ì„ë² ë”©**ì„ ì‚¬ìš©í•œ í–¥ìƒëœ ì¤‘ë³µ ì œê±°ë¥¼ ì§€ì›í•©ë‹ˆë‹¤.

**ê¸°ë³¸ ëª¨ë“œ vs ì˜ë¯¸ ê¸°ë°˜ ëª¨ë“œ**:
- **ê¸°ë³¸ ëª¨ë“œ** (difflib): ë¬¸ìì—´ ê¸°ë°˜ ìœ ì‚¬ë„ ë¹„êµ (ë¹ ë¦„, ì¶”ê°€ ì„¤ì¹˜ ë¶ˆí•„ìš”)
- **ì˜ë¯¸ ê¸°ë°˜ ëª¨ë“œ** (sentence-transformers): ì˜ë¯¸ ê¸°ë°˜ ìœ ì‚¬ë„ ë¹„êµ (ë” ì •í™•, ~100MB ë©”ëª¨ë¦¬ ì‚¬ìš©)

**ì˜ë¯¸ ê¸°ë°˜ ëª¨ë“œì˜ ì¥ì **:
```
"check authentication" â‰ˆ "verify auth"
â†’ ê¸°ë³¸ ëª¨ë“œ: 0.35 ìœ ì‚¬ë„ (ì¤‘ë³µ ê°ì§€ ì•ˆë¨)
â†’ ì˜ë¯¸ ëª¨ë“œ: 0.94 ìœ ì‚¬ë„ (ì¤‘ë³µ ê°ì§€ë¨)
```

**ì„¤ì¹˜ ë°©ë²•** (ì„ íƒì‚¬í•­):
```bash
# 1. ì˜ë¯¸ ê¸°ë°˜ ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements-semantic.txt

# 2. .env íŒŒì¼ì—ì„œ í™œì„±í™”
ACE_USE_SEMANTIC_DEDUP=true
```

**ì°¸ê³ **:
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: ~100MB ì¶”ê°€
- ì„¤ì¹˜í•˜ì§€ ì•Šìœ¼ë©´ ìë™ìœ¼ë¡œ ê¸°ë³¸ ëª¨ë“œ(difflib) ì‚¬ìš©
- ëŒ€ë¶€ë¶„ì˜ ê²½ìš° ê¸°ë³¸ ëª¨ë“œë¡œë„ ì¶©ë¶„í•¨

### 4. ì„¤ì¹˜ í™•ì¸

```bash
# CLI ë™ì‘ í™•ì¸
python -m ace list-datasets

# ì¶œë ¥ ì˜ˆì‹œ:
# ============================================================
# AVAILABLE DATASETS
# ============================================================
#
# labeling:
#   Description: Named entity recognition (FiNER-like)
#   Train: 3 samples
#   Test:  2 samples
#   Total: 5 samples
```

---

## ë°ì´í„°ì…‹ ì¤€ë¹„

### ë°ì´í„° í˜•ì‹ ì´í•´

ACE ë°ì´í„°ì…‹ì€ **question**ê³¼ **ground_truth** ìŒìœ¼ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤:

```python
{
    "question": {
        # ì‘ì—… ì •ì˜ ë° ì…ë ¥ ë°ì´í„°
    },
    "ground_truth": {
        # ì •ë‹µ ë˜ëŠ” ê¸°ëŒ€ ì¶œë ¥
    }
}
```

### ì§€ì›í•˜ëŠ” íƒœìŠ¤í¬ íƒ€ì…

#### 1. LABELING (ê°œì²´ëª… ì¸ì‹)

**ìš©ë„**: í…ìŠ¤íŠ¸ì—ì„œ íŠ¹ì • ê°œì²´(ì¡°ì§, ëˆ, ë‚ ì§œ ë“±)ë¥¼ ì¶”ì¶œí•˜ê³  ë¼ë²¨ë§

**ë°ì´í„° í˜•ì‹**:
```python
{
    "question": {
        "task": "label_spans",
        "text": "Microsoft acquired LinkedIn for $26.2B in June 2016.",
        "labels": ["ORG", "MONEY", "DATE"]
    },
    "ground_truth": {
        "spans": [
            {"text": "Microsoft", "label": "ORG", "start": 0, "end": 9},
            {"text": "LinkedIn", "label": "ORG", "start": 19, "end": 27},
            {"text": "$26.2B", "label": "MONEY", "start": 32, "end": 38},
            {"text": "June 2016", "label": "DATE", "start": 42, "end": 51}
        ]
    }
}
```

#### 2. NUMERIC (ìˆ˜ì‹ ê³„ì‚°)

**ìš©ë„**: ê¸ˆìœµ ê³µì‹, í†µê³„ ê³„ì‚° ë“± ìˆ˜ì¹˜ ì—°ì‚°

**ë°ì´í„° í˜•ì‹**:
```python
{
    "question": {
        "task": "finance_compute",
        "formula": "simple_interest",
        "inputs": {"principal": 1000, "rate_pct": 5, "years": 2}
    },
    "ground_truth": {
        "answer": 100.0,
        "formula": "principal * (rate_pct / 100) * years"
    }
}
```

#### 3. CODE_AGENT (ë¦¬ìŠ¤íŠ¸ ì—°ì‚°)

**ìš©ë„**: ë°ì´í„° ì§‘ê³„, ë³€í™˜ ë“± í”„ë¡œê·¸ë˜ë° ì‘ì—…

**ë°ì´í„° í˜•ì‹**:
```python
{
    "question": {
        "task": "list_aggregate",
        "input": [3, 7, 7, 10],
        "op": "mode"
    },
    "ground_truth": {
        "answer": 7,
        "explanation": "Most frequent element"
    }
}
```

### ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ ì¶”ê°€í•˜ê¸°

#### Step 1: ë°ì´í„° ì •ì˜

`src/ace/datasets.py` íŒŒì¼ì„ ì—´ê³  ìƒˆë¡œìš´ ë°ì´í„°ì…‹ì„ ì¶”ê°€í•©ë‹ˆë‹¤.

**ì˜ˆì œ: ê³ ê° ì§€ì› í‹°ì¼“ ë¶„ë¥˜**

```python
# ============================================================================
# Dataset 4: TICKET_CLASSIFICATION (Customer Support)
# ============================================================================

TICKET_TRAIN = [
    {
        "question": {
            "task": "classify_ticket",
            "text": "I can't log in to my account. Keep getting 'invalid password' error.",
            "categories": ["technical", "billing", "account", "feature_request"]
        },
        "ground_truth": {
            "category": "account",
            "priority": "high",
            "reasoning": "Login issues require immediate attention"
        }
    },
    {
        "question": {
            "task": "classify_ticket",
            "text": "How do I export my data to CSV format?",
            "categories": ["technical", "billing", "account", "feature_request"]
        },
        "ground_truth": {
            "category": "feature_request",
            "priority": "low",
            "reasoning": "User asking about existing feature usage"
        }
    },
    {
        "question": {
            "task": "classify_ticket",
            "text": "I was charged twice this month. Please refund the duplicate charge.",
            "categories": ["technical", "billing", "account", "feature_request"]
        },
        "ground_truth": {
            "category": "billing",
            "priority": "high",
            "reasoning": "Billing issues require immediate resolution"
        }
    },
]

TICKET_TEST = [
    {
        "question": {
            "task": "classify_ticket",
            "text": "The mobile app crashes when I try to upload photos.",
            "categories": ["technical", "billing", "account", "feature_request"]
        },
        "ground_truth": {
            "category": "technical",
            "priority": "high",
            "reasoning": "App crashes are critical bugs"
        }
    },
    {
        "question": {
            "task": "classify_ticket",
            "text": "Can you add dark mode to the dashboard?",
            "categories": ["technical", "billing", "account", "feature_request"]
        },
        "ground_truth": {
            "category": "feature_request",
            "priority": "low",
            "reasoning": "Feature enhancement request"
        }
    },
]
```

#### Step 2: ë°ì´í„°ì…‹ ë“±ë¡

ê°™ì€ íŒŒì¼ì˜ `DATASETS` ë”•ì…”ë„ˆë¦¬ì— ì¶”ê°€:

```python
DATASETS = {
    "labeling": {
        "train": LABELING_TRAIN,
        "test": LABELING_TEST,
        "description": "Named entity recognition (FiNER-like)"
    },
    "numeric": {
        "train": NUMERIC_TRAIN,
        "test": NUMERIC_TEST,
        "description": "Formula-based calculations (finance-like)"
    },
    "code_agent": {
        "train": CODE_AGENT_TRAIN,
        "test": CODE_AGENT_TEST,
        "description": "List operations (AppWorld-like)"
    },
    "ticket": {  # ìƒˆë¡œìš´ ë°ì´í„°ì…‹ ì¶”ê°€
        "train": TICKET_TRAIN,
        "test": TICKET_TEST,
        "description": "Customer support ticket classification"
    },
}
```

#### Step 3: CLIì— ì¶”ê°€ (ì„ íƒì‚¬í•­)

`src/ace/cli.py`ì˜ `choices` ë¦¬ìŠ¤íŠ¸ë¥¼ ì—…ë°ì´íŠ¸:

```python
# 287-290ë²ˆ ì¤„ê³¼ 319-322ë²ˆ ì¤„
choices=["labeling", "numeric", "code_agent", "ticket", "all"],
```

#### Step 4: í‰ê°€ ë¡œì§ ì¶”ê°€

`src/ace/evaluator.py`ì— í‰ê°€ í•¨ìˆ˜ ì¶”ê°€:

```python
def evaluate_ticket(pred: dict, gt: dict) -> Tuple[bool, float]:
    """
    Evaluate ticket classification.

    Args:
        pred: {"category": str, "priority": str, "reasoning": str}
        gt: Same format as pred

    Returns:
        (is_correct, score)
    """
    # Category ì •í™•ë„ (ê°€ì¤‘ì¹˜ 0.7)
    category_correct = pred.get("category", "").lower() == gt.get("category", "").lower()

    # Priority ì •í™•ë„ (ê°€ì¤‘ì¹˜ 0.3)
    priority_correct = pred.get("priority", "").lower() == gt.get("priority", "").lower()

    # ìµœì¢… ì ìˆ˜ ê³„ì‚°
    score = (0.7 if category_correct else 0.0) + (0.3 if priority_correct else 0.0)
    is_correct = (score >= 0.7)  # 70% ì´ìƒì´ë©´ ì •ë‹µìœ¼ë¡œ íŒì •

    return is_correct, score
```

ê·¸ë¦¬ê³  `evaluate_sample` í•¨ìˆ˜ì— íƒœìŠ¤í¬ ì¶”ê°€:

```python
def evaluate_sample(sample: Dict[str, Any], prediction: Dict[str, Any]) -> EvaluationResult:
    """Evaluate a single prediction against ground truth."""
    question = sample["question"]
    ground_truth = sample["ground_truth"]
    task = question.get("task")

    # ... ê¸°ì¡´ ì½”ë“œ ...

    elif task == "classify_ticket":
        is_correct, score = evaluate_ticket(prediction, ground_truth)

    # ... ë‚˜ë¨¸ì§€ ì½”ë“œ ...
```

#### Step 5: ë™ì‘ í™•ì¸

```bash
# ìƒˆ ë°ì´í„°ì…‹ì´ ë“±ë¡ë˜ì—ˆëŠ”ì§€ í™•ì¸
python -m ace list-datasets

# ì¶œë ¥ì— ìƒˆë¡œìš´ í•­ëª©ì´ ë‚˜íƒ€ë‚˜ì•¼ í•¨:
# ticket:
#   Description: Customer support ticket classification
#   Train: 3 samples
#   Test:  2 samples
#   Total: 5 samples
```

---

## ì‹¤í–‰ ê°€ì´ë“œ

### ì „ì²´ í”„ë¡œì„¸ìŠ¤ ê°œìš”

```
1. Baseline í…ŒìŠ¤íŠ¸ (ë¹ˆ í”Œë ˆì´ë¶)
   â†“
2. Offline í•™ìŠµ (í”Œë ˆì´ë¶ ì§„í™”)
   â†“
3. í”Œë ˆì´ë¶ í™•ì¸ (í•™ìŠµ ë‚´ìš© ê²€ì¦)
   â†“
4. Online í…ŒìŠ¤íŠ¸ (ì§„í™”ëœ í”Œë ˆì´ë¶)
   â†“
5. ì„±ëŠ¥ ë¹„êµ (ê°œì„ ë„ ì¸¡ì •)
```

### Step 1: Baseline í…ŒìŠ¤íŠ¸ (ì´ˆê¸° ì„±ëŠ¥ ì¸¡ì •)

ë¹ˆ í”Œë ˆì´ë¶ìœ¼ë¡œ í…ŒìŠ¤íŠ¸í•˜ì—¬ ì´ˆê¸° ì„±ëŠ¥ì„ ì¸¡ì •í•©ë‹ˆë‹¤.

```bash
# í”Œë ˆì´ë¶ ì´ˆê¸°í™” (ë¹„ì–´ìˆëŠ” ìƒíƒœë¡œ ë§Œë“¤ê¸°)
rm -rf storage/playbook.json

# í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ì¶”ë¡  ì‹¤í–‰ (í•™ìŠµ ì—†ì´)
python -m ace online --dataset labeling

# ë˜ëŠ” ëª¨ë“  ë°ì´í„°ì…‹ì— ëŒ€í•´
python -m ace online --dataset all
```

**ì˜ˆìƒ ì¶œë ¥**:
```
============================================================
RESULTS
============================================================
Run ID:     baseline_20241017_143022
Run Dir:    ./runs/baseline_20241017_143022

Accuracy:   40.00%
Avg Score:  0.450
Correct:    2 / 5

Playbook:
  Total items:   0
  Serving items: 0
```

> **ì¤‘ìš”**: ì´ ê²°ê³¼ë¥¼ **ë°˜ë“œì‹œ ê¸°ë¡**í•˜ì„¸ìš”. ë‚˜ì¤‘ì— ê°œì„ ë„ë¥¼ ë¹„êµí•  ê¸°ì¤€ì ì…ë‹ˆë‹¤.

### Step 2: Offline í•™ìŠµ (í”Œë ˆì´ë¶ ì§„í™”)

í•™ìŠµ ë°ì´í„°ë¡œ í”Œë ˆì´ë¶ì„ ì§„í™”ì‹œí‚µë‹ˆë‹¤.

```bash
# íŠ¹ì • ë°ì´í„°ì…‹ìœ¼ë¡œ í•™ìŠµ (2 ì—í¬í¬)
python -m ace offline --dataset labeling --epochs 2

# ëª¨ë“  ë°ì´í„°ì…‹ìœ¼ë¡œ í•™ìŠµ
python -m ace offline --dataset all --epochs 3

# ì²˜ìŒë¶€í„° ë‹¤ì‹œ ì‹œì‘ (ê¸°ì¡´ í”Œë ˆì´ë¶ ë¦¬ì…‹)
python -m ace offline --dataset all --epochs 2 --reset
```

**ì‹¤í–‰ ì¤‘ í™”ë©´**:
```
2024-10-17 14:35:12 [INFO] ace.pipeline: Starting offline adaptation...
2024-10-17 14:35:12 [INFO] ace.pipeline: Epoch 1/2
2024-10-17 14:35:15 [INFO] ace.pipeline: Sample 1/3 - Score: 0.85
2024-10-17 14:35:18 [INFO] ace.pipeline: Sample 2/3 - Score: 1.00
2024-10-17 14:35:21 [INFO] ace.pipeline: Sample 3/3 - Score: 0.92

Epoch 1 - Accuracy: 91.67%
  Playbook operations applied: 5 items added

2024-10-17 14:35:22 [INFO] ace.pipeline: Epoch 2/2
...
```

**í•™ìŠµ ì™„ë£Œ í›„ ì¶œë ¥**:
```
============================================================
RESULTS
============================================================
Run ID:     offline_labeling_20241017_143522
Run Dir:    ./runs/offline_labeling_20241017_143522

Accuracy:   100.00%
Avg Score:  1.000
Correct:    3 / 3

Playbook:
  Total items:   8
  Serving items: 8
```

### Step 3: í”Œë ˆì´ë¶ í™•ì¸ (í•™ìŠµ ë‚´ìš© ê²€ì¦)

í”Œë ˆì´ë¶ì— ì–´ë–¤ ì§€ì‹ì´ ì¶•ì ë˜ì—ˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.

```bash
# ê¸°ë³¸ í†µê³„ í™•ì¸
python -m ace stats

# ìƒì„¸ ì •ë³´ í™•ì¸ (ê° í•­ëª©ì˜ ë‚´ìš©ê¹Œì§€)
python -m ace stats --verbose
```

**ê¸°ë³¸ í†µê³„ ì¶œë ¥**:
```
============================================================
PLAYBOOK STATISTICS
============================================================
Total items:      8
Serving items:    8
Deprecated items: 0
Harmful items:    0

By category:
  strategy    : 3
  formula     : 2
  pitfall     : 1
  checklist   : 1
  example     : 1
```

**ìƒì„¸ ì •ë³´ ì¶œë ¥** (`--verbose`):
```
============================================================
ITEM DETAILS
============================================================

[a3f9e2b4c1d8] strategy - active
  Title: Four-digit Year Recognition
  Helpful: 2 | Harmful: 0
  Tags: labeling, date, pattern

  Content: When encountering four consecutive digits in text (e.g., "2024"),
  classify them as DATE entities. This pattern is reliable for year recognition
  in financial and news contexts.

[b7c4d8f2e1a9] formula - active
  Title: Simple Interest Formula
  Helpful: 3 | Harmful: 0
  Tags: finance, numeric, interest

  Content: Simple Interest = Principal Ã— (Rate / 100) Ã— Years
  Example: $1,000 at 5% for 2 years = 1000 Ã— 0.05 Ã— 2 = $100

[c8e1a9b4f3d2] pitfall - active
  Title: Off-by-one in List Indexing
  Helpful: 1 | Harmful: 0
  Tags: code_agent, list, indexing

  Content: Remember that list indices start at 0, not 1. When asked for
  "the 3rd element", use index 2, not 3.

...
```

### Step 4: Online í…ŒìŠ¤íŠ¸ (ì§„í™”ëœ í”Œë ˆì´ë¶ë¡œ ì¶”ë¡ )

í•™ìŠµëœ í”Œë ˆì´ë¶ì„ ì‚¬ìš©í•˜ì—¬ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ì¶”ë¡ í•©ë‹ˆë‹¤.

```bash
# í•™ìŠµëœ í”Œë ˆì´ë¶ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
python -m ace online --dataset labeling

# ì¶”ë¡  ì¤‘ì—ë„ í•™ìŠµ í™œì„±í™” (incremental learning)
python -m ace online --dataset labeling --enable-learning
```

**ì¶œë ¥ ì˜ˆì‹œ**:
```
============================================================
RESULTS
============================================================
Run ID:     online_labeling_20241017_144022
Run Dir:    ./runs/online_labeling_20241017_144022

Accuracy:   100.00%
Avg Score:  1.000
Correct:    2 / 2

Playbook:
  Total items:   8
  Serving items: 8
```

---

## ì„±ëŠ¥ ë¹„êµ

### ë©”íŠ¸ë¦­ ìˆ˜ì§‘

ê° ì‹¤í–‰ ë‹¨ê³„ì—ì„œ ë‹¤ìŒ ì •ë³´ë¥¼ ê¸°ë¡í•˜ì„¸ìš”:

| ë‹¨ê³„ | Accuracy | Correct | Total | Playbook Items |
|------|----------|---------|-------|----------------|
| Baseline (Before) | 40.00% | 2 | 5 | 0 |
| After Training | 100.00% | 5 | 5 | 8 |

### ê°œì„ ë„ ê³„ì‚°

```python
# ì ˆëŒ€ ê°œì„ ë„
absolute_improvement = accuracy_after - accuracy_before
# 100.00% - 40.00% = +60.00%

# ìƒëŒ€ ê°œì„ ë„
relative_improvement = (accuracy_after / accuracy_before - 1) * 100
# (100.00 / 40.00 - 1) Ã— 100 = +150%
```

### ìë™í™”ëœ ë¹„êµ ìŠ¤í¬ë¦½íŠ¸

`scripts/compare_performance.py` íŒŒì¼ì„ ìƒì„±:

```python
"""
ì„±ëŠ¥ ë¹„êµ ìŠ¤í¬ë¦½íŠ¸
"""
import json
from pathlib import Path
from typing import Dict, List


def load_run_results(run_dir: str) -> Dict:
    """Load results from a run directory."""
    metadata_path = Path(run_dir) / "run_metadata.json"
    with open(metadata_path) as f:
        return json.load(f)


def compare_runs(baseline_dir: str, trained_dir: str):
    """Compare baseline and trained runs."""
    baseline = load_run_results(baseline_dir)
    trained = load_run_results(trained_dir)

    baseline_acc = baseline["final_metrics"]["accuracy"]
    trained_acc = trained["final_metrics"]["accuracy"]

    abs_improvement = trained_acc - baseline_acc
    rel_improvement = (trained_acc / baseline_acc - 1) * 100 if baseline_acc > 0 else 0

    print("\n" + "="*60)
    print("PERFORMANCE COMPARISON")
    print("="*60)
    print(f"\nBaseline Performance:")
    print(f"  Accuracy: {baseline_acc:.2%}")
    print(f"  Correct:  {baseline['final_metrics']['correct']}/{baseline['final_metrics']['total']}")
    print(f"  Playbook: {baseline['playbook_stats']['total_items']} items")

    print(f"\nTrained Performance:")
    print(f"  Accuracy: {trained_acc:.2%}")
    print(f"  Correct:  {trained['final_metrics']['correct']}/{trained['final_metrics']['total']}")
    print(f"  Playbook: {trained['playbook_stats']['total_items']} items")

    print(f"\nImprovement:")
    print(f"  Absolute: {abs_improvement:+.2%}")
    print(f"  Relative: {rel_improvement:+.1f}%")
    print(f"  Playbook Growth: +{trained['playbook_stats']['total_items'] - baseline['playbook_stats']['total_items']} items")
    print()


if __name__ == "__main__":
    import sys

    if len(sys.argv) != 3:
        print("Usage: python scripts/compare_performance.py <baseline_run_dir> <trained_run_dir>")
        sys.exit(1)

    compare_runs(sys.argv[1], sys.argv[2])
```

**ì‚¬ìš© ë°©ë²•**:
```bash
python scripts/compare_performance.py \
    ./runs/baseline_20241017_143022 \
    ./runs/online_labeling_20241017_144022
```

---

## ì‹¤ì „ ì˜ˆì œ

### ì‹œë‚˜ë¦¬ì˜¤: ë²•ë¥  ë¬¸ì„œ ê°œì²´ëª… ì¸ì‹

ë²•ë¥  ë¬¸ì„œì—ì„œ ë‹¹ì‚¬ì, ë‚ ì§œ, ê¸ˆì•¡ ë“±ì„ ì¶”ì¶œí•˜ëŠ” ì‹œìŠ¤í…œì„ ë§Œë“¤ì–´ë´…ì‹œë‹¤.

#### 1. ë°ì´í„° ì¤€ë¹„

`src/ace/datasets.py`ì— ì¶”ê°€:

```python
LEGAL_TRAIN = [
    {
        "question": {
            "task": "label_spans",
            "text": "On March 15, 2024, John Doe filed a lawsuit against ABC Corp for $500,000.",
            "labels": ["DATE", "PERSON", "ORG", "MONEY"]
        },
        "ground_truth": {
            "spans": [
                {"text": "March 15, 2024", "label": "DATE", "start": 3, "end": 17},
                {"text": "John Doe", "label": "PERSON", "start": 19, "end": 27},
                {"text": "ABC Corp", "label": "ORG", "start": 49, "end": 57},
                {"text": "$500,000", "label": "MONEY", "start": 62, "end": 70}
            ]
        }
    },
    {
        "question": {
            "task": "label_spans",
            "text": "The defendant, Jane Smith, must pay damages by December 31, 2024.",
            "labels": ["PERSON", "DATE"]
        },
        "ground_truth": {
            "spans": [
                {"text": "Jane Smith", "label": "PERSON", "start": 15, "end": 25},
                {"text": "December 31, 2024", "label": "DATE", "start": 47, "end": 64}
            ]
        }
    },
]

LEGAL_TEST = [
    {
        "question": {
            "task": "label_spans",
            "text": "XYZ Inc. agreed to settle with Robert Johnson for â‚¬2.5M on July 1st.",
            "labels": ["ORG", "PERSON", "MONEY", "DATE"]
        },
        "ground_truth": {
            "spans": [
                {"text": "XYZ Inc.", "label": "ORG", "start": 0, "end": 8},
                {"text": "Robert Johnson", "label": "PERSON", "start": 31, "end": 45},
                {"text": "â‚¬2.5M", "label": "MONEY", "start": 50, "end": 55},
                {"text": "July 1st", "label": "DATE", "start": 59, "end": 67}
            ]
        }
    },
]

# DATASETSì— ë“±ë¡
DATASETS["legal"] = {
    "train": LEGAL_TRAIN,
    "test": LEGAL_TEST,
    "description": "Legal document entity extraction"
}
```

#### 2. Baseline ì¸¡ì •

```bash
rm -rf storage/playbook.json
python -m ace online --dataset legal
```

**ì˜ˆìƒ ê²°ê³¼**: 50-60% ì •í™•ë„ (ë²•ë¥  ë„ë©”ì¸ íŠ¹ìˆ˜ì„±ìœ¼ë¡œ ë‚®ìŒ)

#### 3. í•™ìŠµ ì‹¤í–‰

```bash
python -m ace offline --dataset legal --epochs 3
```

#### 4. ì¬í…ŒìŠ¤íŠ¸

```bash
python -m ace online --dataset legal
```

**ì˜ˆìƒ ê²°ê³¼**: 80-100% ì •í™•ë„ (ë²•ë¥  ìš©ì–´ íŒ¨í„´ í•™ìŠµ)

#### 5. í•™ìŠµ ë‚´ìš© í™•ì¸

```bash
python -m ace stats --verbose
```

**ì˜ˆìƒë˜ëŠ” í•™ìŠµ ë‚´ìš©**:
- "ìœ ë¡œ í™”í ê¸°í˜¸(â‚¬) ì¸ì‹ ì „ëµ"
- "ë²•ë¥  ë¬¸ì„œì˜ ë‚ ì§œ í‘œí˜„ íŒ¨í„´"
- "íšŒì‚¬ëª… ì‹ë³„ ì²´í¬ë¦¬ìŠ¤íŠ¸ (Inc., Corp, Ltd ë“±)"

---

## ë¬¸ì œ í•´ê²°

### í”í•œ ì˜¤ë¥˜ì™€ í•´ê²°ì±…

#### 1. `ModuleNotFoundError: No module named 'anthropic'`

**ì›ì¸**: ì˜ì¡´ì„±ì´ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ

**í•´ê²°**:
```bash
pip install -r requirements.txt
```

#### 2. `Error: ANTHROPIC_API_KEY not found`

**ì›ì¸**: API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ

**í•´ê²°**:
```bash
# .env íŒŒì¼ ìƒì„± ë° í¸ì§‘
cp .env.example .env
# ANTHROPIC_API_KEY=your_key_here ì¶”ê°€
```

#### 3. `FileNotFoundError: [Errno 2] No such file or directory: './storage/playbook.json'`

**ì›ì¸**: í”Œë ˆì´ë¶ íŒŒì¼ì´ ì—†ìŒ (ì˜¨ë¼ì¸ ëª¨ë“œë¥¼ ë¨¼ì € ì‹¤í–‰í•œ ê²½ìš°)

**í•´ê²°**:
```bash
# ë¨¼ì € ì˜¤í”„ë¼ì¸ í•™ìŠµ ì‹¤í–‰
python -m ace offline --dataset labeling --epochs 2

# ê·¸ ë‹¤ìŒ ì˜¨ë¼ì¸ ì¶”ë¡ 
python -m ace online --dataset labeling
```

#### 4. ì •í™•ë„ê°€ ê°œì„ ë˜ì§€ ì•ŠìŒ

**ê°€ëŠ¥í•œ ì›ì¸**:
1. **í•™ìŠµ ë°ì´í„° ë¶€ì¡±**: ìµœì†Œ 5ê°œ ì´ìƒì˜ train ìƒ˜í”Œ í•„ìš”
2. **ì—í¬í¬ ë¶€ì¡±**: `--epochs 3` ì´ìƒìœ¼ë¡œ ì‹¤í–‰
3. **ë°ì´í„° í’ˆì§ˆ**: ground_truthê°€ ì •í™•í•œì§€ í™•ì¸

**í•´ê²°**:
```bash
# ë” ë§ì€ ì—í¬í¬ë¡œ ì¬í•™ìŠµ
python -m ace offline --dataset your_dataset --epochs 5 --reset

# í”Œë ˆì´ë¶ ìƒíƒœ í™•ì¸
python -m ace stats --verbose
```

#### 5. API ë¹„ìš© ì œì–´

**ë¬¸ì œ**: í•™ìŠµ ì¤‘ API ë¹„ìš©ì´ ê±±ì •ë¨

**í•´ê²°**:
1. ì‘ì€ ë°ì´í„°ì…‹(3-5ê°œ ìƒ˜í”Œ)ë¡œ ì‹œì‘
2. `ACE_MAX_TOKENS`ë¥¼ ë‚®ê²Œ ì„¤ì • (1024)
3. Mock í…ŒìŠ¤íŠ¸ë¡œ í”„ë¡œì„¸ìŠ¤ ë¨¼ì € ê²€ì¦ (`scripts/test_playbook_evolution.py` ì°¸ê³ )

```bash
# .envì— í† í° ì œí•œ ì¶”ê°€
ACE_MAX_TOKENS=1024
```

#### 6. í”Œë ˆì´ë¶ì´ ë„ˆë¬´ ì»¤ì§

**ë¬¸ì œ**: í”Œë ˆì´ë¶ ì•„ì´í…œì´ 100ê°œ ì´ìƒ

**ì›ì¸**: ì¤‘ë³µ ì œê±° ì„ê³„ê°’ì´ ë„ˆë¬´ ë‚®ìŒ

**í•´ê²°**:
```bash
# .envì—ì„œ ì„ê³„ê°’ ì¡°ì •
ACE_DEDUP_SIMILARITY=0.95  # ë” ì—„ê²©í•œ ì¤‘ë³µ ì œê±° (ê¸°ë³¸ê°’: 0.92)
ACE_MAX_OPERATIONS_PER_CURATOR=10  # í•œ ë²ˆì— ì¶”ê°€ë˜ëŠ” í•­ëª© ì œí•œ (ê¸°ë³¸ê°’: 20)
```

---

## ë‹¤ìŒ ë‹¨ê³„

### ì¶”ê°€ í•™ìŠµ ìë£Œ

- **README.md**: ì „ì²´ ì•„í‚¤í…ì²˜ ë° CLI ëª…ë ¹ì–´
- **CLAUDE.md**: ê°œë°œ ê°€ì´ë“œë¼ì¸
- **report.md**: ì§„í™” í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë° ì„±ëŠ¥ ë¶„ì„

### ê³ ê¸‰ ê¸°ëŠ¥

1. **Incremental Learning**: ì¶”ë¡  ì¤‘ì—ë„ í•™ìŠµ í™œì„±í™”
   ```bash
   python -m ace online --dataset labeling --enable-learning
   ```

2. **Early Stopping**: ìˆ˜ë ´ ì‹œ ìë™ ì¢…ë£Œ
   ```bash
   python -m ace offline --dataset labeling --epochs 10 --patience 3
   ```

3. **Custom Evaluator**: ìì‹ ë§Œì˜ í‰ê°€ ë¡œì§ êµ¬í˜„
   - `src/ace/evaluator.py`ì˜ `evaluate_sample` í•¨ìˆ˜ ìˆ˜ì •

### í”„ë¡œë•ì…˜ ë°°í¬

í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œ ì‚¬ìš©í•˜ë ¤ë©´:

1. **í”Œë ˆì´ë¶ ë²„ì „ ê´€ë¦¬**: Gitìœ¼ë¡œ `storage/playbook.json` ì¶”ì 
2. **A/B í…ŒìŠ¤íŠ¸**: ë¹ˆ í”Œë ˆì´ë¶ vs ì§„í™”ëœ í”Œë ˆì´ë¶ ì„±ëŠ¥ ë¹„êµ
3. **ëª¨ë‹ˆí„°ë§**: `runs/` ë””ë ‰í† ë¦¬ì˜ ë¡œê·¸ ë¶„ì„
4. **ì§€ì†ì  ê°œì„ **: ìƒˆë¡œìš´ ë°ì´í„°ë¡œ ì£¼ê¸°ì  ì¬í•™ìŠµ

---

## ìš”ì•½

ACE í”„ë ˆì„ì›Œí¬ ì‚¬ìš© íë¦„:

```
1. í™˜ê²½ ì„¤ì • â†’ pyenv + pip install + API key
2. ë°ì´í„° ì¤€ë¹„ â†’ datasets.pyì— question/ground_truth ì¶”ê°€
3. Baseline â†’ python -m ace online (ë¹ˆ í”Œë ˆì´ë¶)
4. í•™ìŠµ â†’ python -m ace offline --epochs 3
5. ê²€ì¦ â†’ python -m ace stats --verbose
6. ì¬í…ŒìŠ¤íŠ¸ â†’ python -m ace online (ì§„í™”ëœ í”Œë ˆì´ë¶)
7. ë¹„êµ â†’ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë¶„ì„
```

**í•µì‹¬ ì›ì¹™**:
- ì‘ì€ ë°ì´í„°ì…‹ìœ¼ë¡œ ì‹œì‘ (3-5 ìƒ˜í”Œ)
- ë°˜ë“œì‹œ baseline ì¸¡ì • í›„ í•™ìŠµ
- í”Œë ˆì´ë¶ ë‚´ìš©ì„ ì •ê¸°ì ìœ¼ë¡œ ê²€í† 
- ë„ë©”ì¸ ì§€ì‹ì´ ì¶•ì ë˜ëŠ” ê³¼ì •ì„ ê´€ì°°

ì´ì œ ìì‹ ì˜ ë°ì´í„°ë¡œ ACE í”„ë ˆì„ì›Œí¬ë¥¼ ì‚¬ìš©í•´ë³´ì„¸ìš”! ğŸš€
